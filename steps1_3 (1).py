# -*- coding: utf-8 -*-
"""Steps1-3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k1JnIyOG3fZlq1Kw9FKjH-ftAJA7zII2
"""

import numpy as np
import math
from matplotlib import pyplot as plt
import time
from numba import jit
from numba import int64, int32, float32, float64, prange, types
from numba.experimental import jitclass
from numba.typed import List
from numba import njit
from numba import prange

y_of_tank_ceiling = 0.
tank_ceiling_velocity = 3.
g = -9.8
dt = 0.005
GRID_SIZE = 50
# obstruction = np.zeros((GRID_SIZE,GRID_SIZE))
# obstruction[GRID_SIZE-12:GRID_SIZE,GRID_SIZE-12:GRID_SIZE] = 99
obstruction = np.zeros((GRID_SIZE,GRID_SIZE),dtype=int)
obstruction[0:30,12:19] = 99
obstruction[35:GRID_SIZE,12:19] = 99
PARTICLE_RADIUS = 0.25
MAX_PARTICLES_PER_CELL = 4
obstruct_u = np.ones((GRID_SIZE,GRID_SIZE+1),dtype=int)
obstruct_v = np.ones((GRID_SIZE+1,GRID_SIZE),dtype=int)

# add in all the obstruction based on predefined
for row in range(0,GRID_SIZE):
  obstruct_u[row][0] = 0
  obstruct_u[row][GRID_SIZE] = 0
for row in range(0,GRID_SIZE):
  for col in range(0,GRID_SIZE):
    if col == 0 and obstruction[row][col] == 99:
      obstruct_u[row][col] = 888
    elif col == GRID_SIZE-1 and obstruction[row][col] == 99:
      obstruct_u[row][col+1] = 888
    else:
      if obstruction[row][col] == 99 and obstruction[row][col-1] == 99:
        obstruct_u[row][col] = 888
      if obstruction[row][col] == 99 and obstruction[row][col+1] == 99:
        obstruct_u[row][col+1] = 888
      if obstruction[row][col] == 99 and obstruction[row][col-1] == 0:
        obstruct_u[row][col] = 0
      if obstruction[row][col] == 0 and obstruction[row][col-1] == 99:
        obstruct_u[row][col] = 0

for col in range(0,GRID_SIZE):
  obstruct_v[0][col] = 0
  obstruct_v[GRID_SIZE][col] = 0
for row in range(0,GRID_SIZE):
  for col in range(0,GRID_SIZE):
    if row == 0 and obstruction[row][col] == 99:
      obstruct_v[row][col] = 888
    elif row == GRID_SIZE-1 and obstruction[row][col] == 99:
      obstruct_v[row+1][col] = 888
    else:
      if obstruction[row][col] == 99 and obstruction[row-1][col] == 99:
        obstruct_v[row][col] = 888
      if obstruction[row][col] == 99 and obstruction[row+1][col] == 99:
        obstruct_v[row+1][col] = 888
      if obstruction[row][col] == 99 and obstruction[row-1][col] == 0:
        obstruct_v[row][col] = 0
      if obstruction[row][col] == 0 and obstruction[row-1][col] == 99:
        obstruct_v[row][col] = 0

spec = [("x", float64),("y",float64),("u",float64),("v",float64)]
@jitclass(spec)
class Particle:
    def __init__(self, x, y, u, v):
        self.x = x
        self.y = y
        self.u = u
        self.v = v

    def update_position(self):
      # update position only if the particle is still on the grid
      if self.x > 0 and self.x < GRID_SIZE:
          self.v += g * dt
          self.x = self.x + self.u * dt
          self.y = self.y + (-1)*self.v * dt

@jit((Particle.class_type.instance_type, Particle.class_type.instance_type))
def detect_collision(p1, p2):
    # detect collision only if the particles are still on the grid
    distance = np.sqrt((p1.x - p2.x)*(p1.x - p2.x) + (p1.y - p2.y)*(p1.y - p2.y))
    if distance < 2 * PARTICLE_RADIUS:
        overlap = 2 * PARTICLE_RADIUS - distance
        direction_vector = np.array([p2.x - p1.x, p2.y - p1.y])
        if np.linalg.norm(direction_vector) > 0:
            direction_vector /= np.linalg.norm(direction_vector)
        displacement = direction_vector * overlap / 2
        p1.x -= displacement[0]
        p1.y -= displacement[1]
        p2.x += displacement[0]
        p2.y += displacement[1]

@jit((Particle.class_type.instance_type, float64, float64))
def border_collision(p1,y_of_tank_ceiling,tank_ceiling_velocity):
    if p1.x < PARTICLE_RADIUS:
      p1.x = 2 * PARTICLE_RADIUS - p1.x

    if p1.x > GRID_SIZE - PARTICLE_RADIUS:
      p1.x = 2 * (GRID_SIZE - PARTICLE_RADIUS) - p1.x

    if p1.y < PARTICLE_RADIUS:
      p1.y = 2 * PARTICLE_RADIUS - p1.y

    if p1.y > GRID_SIZE - PARTICLE_RADIUS:
      p1.y = 2 * (GRID_SIZE - PARTICLE_RADIUS) - p1.y

    x = p1.x
    y = p1.y

    # if water particle penetrates into the top of the tank, push it out
    if y < y_of_tank_ceiling:
      p1.y = y_of_tank_ceiling + PARTICLE_RADIUS
      p1.v = tank_ceiling_velocity

    # if hit obstruction, push particle back out
    if obstruction[int(y)][int(x)] == 99:
        p1.x = p1.x - p1.u * dt
        p1.y = p1.y - p1.v * dt

@jit(nopython=True)
def simulate_particles(steps):
    saved_images = []
    particles = []

    # create initial particle positions
    water_height = 40
    water_width = 12
    for row in range(0,int(water_height/(2*PARTICLE_RADIUS))):
      for col in range(0,int(water_width/(2*PARTICLE_RADIUS))):
        anti_row = int(GRID_SIZE/(2*PARTICLE_RADIUS))-row
        x = (2*PARTICLE_RADIUS)*col+PARTICLE_RADIUS
        y = (2*PARTICLE_RADIUS)*anti_row-PARTICLE_RADIUS
        if obstruction[int(y)][int(x)] != 99:
          particle = Particle(x, y, 0, 0)
          particles.append(particle)

    y_of_tank_ceiling = GRID_SIZE - water_height

    #Advect particles -> particle-particle collision -> border collision ->
    #transfer u-velocities -> transfer v-velocities -> calculate particle density ->
    #enforce zero-divergence + incompressability -> send data back to the particles

    for step in range(steps):
        #advecting particles
        for particle in particles:
            particle.update_position()

        for count in range(0,12):
          #particle collision detection
          for i in range(len(particles)):
              for j in range(len(particles)):
                  detect_collision(particles[i], particles[j])

        tank_ceiling_velocity = 0.05  # range of 0.01 to 0.05
        y_of_tank_ceiling = y_of_tank_ceiling + dt * tank_ceiling_velocity
        for i in range(len(particles)):
            #border collision
            border_collision(particles[i], y_of_tank_ceiling, tank_ceiling_velocity)

        #transfering u and v velocities to grid
        u_grid = np.zeros((GRID_SIZE,GRID_SIZE+1))
        v_grid = np.zeros((GRID_SIZE+1,GRID_SIZE))
        u_weights = np.zeros((GRID_SIZE,GRID_SIZE+1))
        v_weights = np.zeros((GRID_SIZE+1,GRID_SIZE))

        for p in particles:
            col = int(p.x)
            row = int(p.y)

            # for u_weights
            dx = p.x - int(p.x)
            dy = p.y - int(p.y)

            if 0 <= col < GRID_SIZE and 0 <= row < GRID_SIZE:
                if 0 <= math.floor(p.y+0.5) < GRID_SIZE and obstruct_u[math.floor(p.y+0.5)][math.floor(p.x)] ==1:
                  # lower left
                  u_grid[math.floor(p.y+0.5)][math.floor(p.x)] += p.u * (1 - dx) * (1 - dy)
                  u_weights[math.floor(p.y+0.5)][math.floor(p.x)] += (1 - dx) * (1 - dy)

                if 0 <= math.floor(p.y+0.5) < GRID_SIZE and obstruct_u[math.floor(p.y+0.5)][math.ceil(p.x)] ==1:
                  # lower right
                  u_grid[math.floor(p.y+0.5)][math.ceil(p.x)] += p.u * (dx) * (1 - dy)
                  u_weights[math.floor(p.y+0.5)][math.ceil(p.x)] += (dx) * (1 - dy)

                if obstruct_u[math.floor(p.y-0.5)][math.floor(p.x)] ==1:
                  # upper left
                  u_grid[math.floor(p.y-0.5)][math.floor(p.x)] += p.u * (1-dx) * (dy)
                  u_weights[math.floor(p.y-0.5)][math.floor(p.x)] += (1-dx) * (dy)

                if obstruct_u[math.floor(p.y-0.5)][math.ceil(p.x)] ==1:
                  # upper right
                  u_grid[math.floor(p.y-0.5)][math.ceil(p.x)] += p.u * (dx) * (dy)
                  u_weights[math.floor(p.y-0.5)][math.ceil(p.x)] += (dx) * (dy)

            # for v_weights
            dy = math.ceil(p.y)-p.y
            dx = p.x - math.floor(p.x) - 0.5 if (p.x-math.floor(p.x)>0.5) else p.x-math.floor(p.x) + 0.5

            if 0 <= col < GRID_SIZE and 0 <= row < GRID_SIZE:
                if obstruct_v[math.floor(p.y)][math.floor(p.x+0.5)] ==1:
                    # lower left
                    v_grid[math.floor(p.y)][math.floor(p.x+0.5)] += p.v * (1 - dx) * (1 - dy)
                    v_weights[math.floor(p.y)][math.floor(p.x+0.5)] += (1 - dx) * (1 - dy)

                if obstruct_v[math.floor(p.y)][math.ceil(p.x+0.5)] ==1:
                    # lower right
                    v_grid[math.floor(p.y)][math.ceil(p.x+0.5)] += p.v * (dx) * (1 - dy)
                    v_weights[math.floor(p.y)][math.ceil(p.x+0.5)] += (dx) * (1 - dy)

                if obstruct_v[math.ceil(p.y)][math.floor(p.x+0.5)] ==1:
                    # upper left
                    v_grid[math.ceil(p.y)][math.floor(p.x+0.5)] += p.v * (1-dx) * (dy)
                    v_weights[math.ceil(p.y)][math.floor(p.x+0.5)] += (1-dx) * (dy)

                if obstruct_v[math.ceil(p.y)][math.ceil(p.x+0.5)] ==1:
                    # upper right
                    v_grid[math.ceil(p.y)][math.ceil(p.x+0.5)] += p.v * (dx) * (dy)
                    v_weights[math.ceil(p.y)][math.ceil(p.x+0.5)] += (dx) * (dy)

        for row in range(0,GRID_SIZE):
          for col in range(0,GRID_SIZE+1):
            if u_weights[row][col] != 0:
              u_grid[row][col] = u_grid[row][col]/u_weights[row][col]

        for row in range(0,GRID_SIZE+1):
          for col in range(0,GRID_SIZE):
            if v_weights[row][col] != 0:
              v_grid[row][col] = v_grid[row][col]/v_weights[row][col]

        #zero-divergence
        density = np.zeros((GRID_SIZE, GRID_SIZE))
        for p in particles:
          y = int(p.y)
          x = int(p.x)
          if 0<x<GRID_SIZE-1 and 0<y<GRID_SIZE-1:
            density[y][x] += 1

        for _ in range(50):
            for row in range(GRID_SIZE):
                for col in range(GRID_SIZE):
                    if density[row, col] > 0:
                        sides = 4
                        if obstruct_v[row,col] == 1:
                          above = v_grid[row, col]
                        else:
                          above = 0
                          sides = sides -1

                        if obstruct_v[row + 1, col] == 1:
                          below = v_grid[row + 1, col]
                        else:
                          below = 0
                          sides = sides - 1

                        if obstruct_u[row, col+1] == 1:
                          right = u_grid[row, col+1]
                        else:
                          right = 0
                          sides -= 1

                        if obstruct_u[row, col] == 1:
                          left = u_grid[row, col]
                        else:
                          left = 0
                          sides -= 1

                        # etc etc
                        below = v_grid[row + 1, col] if row < GRID_SIZE - 1 else 0
                        right = u_grid[row, col + 1] if col < GRID_SIZE - 1 else 0
                        left = u_grid[row, col] if col > 0 else 0
                        #Incompressability trick
                        d = 1.9 * (above - below + right - left) - (density[row, col] - 4)

                        # Counting sides
                        # if one of the sides is a no-slip condition, you need to ignore it.
                        # this means you will only have 3 sides.

                        # Updating grids
                        # fix this to only update the sides that should be updated
                        if row > 0 and obstruct_v[row , col] == 1:
                          v_grid[row, col] -= d/sides

                        if row > GRID_SIZE - 1 and obstruct_v[row+1, col] == 1:
                          v_grid[row+1, col] += d/sides

                        if col < GRID_SIZE - 1 and obstruct_u[row, col+1] == 1:
                          u_grid[row, col+1] -= d/sides

                        if col > 0 and obstruct_u[row, col] == 1:
                          u_grid[row, col] += d / sides

        #TRANSFER THE GRID VELOCITIES BACK TO THE PARTICLES
        for p in particles:
            col = int(p.x)
            row = int(p.y)

            # dx = p.x - int(p.x)
            # dy = p.y - int(p.y)

            # transfer u velocity back to particles
            x,y=p.x,p.y
            dx = x-math.floor(x)
            if y-math.floor(y) < 0.5:
              dy = 0.5 - (y-math.floor(y))
            else:
              dy = 1.5 - (y-math.floor(y))

            if row < GRID_SIZE-1 and 0 < col < GRID_SIZE-1 and obstruct_u[row][col] == 1:
                p.u = ( (u_grid[row, col+1] * (dx * dy)) +
                        (u_grid[row, col] * (1-dx) * dy) +
                        (u_grid[row+1, col] * (1-dx) * (1-dy)) +
                        (u_grid[row+1, col+1] * dx *(1-dy)) )

            # transfer v velocity back to particles
            dy = math.ceil(p.y)-p.y
            dx = p.x - math.floor(p.x) - 0.5 if (p.x-math.floor(p.x)>0.5) else p.x-math.floor(p.x) + 0.5

            if col < GRID_SIZE-1 and 0 < row < GRID_SIZE-1 and obstruct_v[row][col] ==1:
                p.v = ( (v_grid[row, col+1] * (dx*dy)) +
                        (v_grid[row, col] * (1-dx) * dy) +
                        (v_grid[row+1, col] * (1-dx) * (1-dy)) +
                        (v_grid[row+1, col+1] * dx * (1-dy)) )

        if step%50 ==0:
          density = np.zeros((GRID_SIZE, GRID_SIZE))
          for p in particles:
              if 0 <= int(p.x) < GRID_SIZE and 0 <= int(p.y) < GRID_SIZE:
                  density[int(p.y)][int(p.x)] += 1
          for row in range(0,GRID_SIZE):
              for col in range(0,GRID_SIZE):
                if obstruction[row][col] == 99:
                  density[row][col] = 99
          saved_images.append(density)

    return saved_images

start = time.time()
saved_images = simulate_particles(1000)
end = time.time()
print(end-start)

for count in range(0,len(saved_images)):
  my_image = saved_images[count]
  my_image[my_image>90] = 'nan'
  plt.imshow(my_image,cmap='jet',interpolation='nearest')
  plt.colorbar()
  plt.show()

import numpy as np
from matplotlib import pyplot as plt
GRID_SIZE=50
obstruction = np.zeros((GRID_SIZE,GRID_SIZE))
obstruction[0:30,12:19] = 99
obstruction[35:GRID_SIZE,12:19] = 99
plt.imshow(obstruction)
plt.show()

from google.colab import drive
drive.mount('/content/drive')

import random
from matplotlib import pyplot as plt
from scipy import interpolate
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from keras import backend as K
import keras
import tensorflow as tf
import pandas as pd

tot_rows,tot_columns = 256, 362
good = False
total_points = 8
while good == False:
  max = 0
  landscape = np.zeros((tot_rows,tot_columns),dtype=int)
  x_points = []
  for count in range(0,total_points):
    # x_points are evenly spaced from [0,362]
    x_points.append(int((tot_columns-1)/(total_points-1))*count)
  y_points = []
  for _ in range(0,total_points):
    y_points.append(random.randint(180,254))

  tck = interpolate.splrep(x_points,y_points)
  for col in range(0,tot_columns):
    row_value = int(interpolate.splev(col,tck))
    if row_value > max:
      max = row_value
    if row_value <= tot_rows - 1:
      landscape[row_value][col] = 99
  if max < tot_rows - 1:
    good = True
# sweep from bottom to top
for col in range(0,tot_columns):
  row = tot_rows - 1
  while landscape[row][col] != 99:
    landscape[row][col] = 99
    row = row - 1
plt.imshow(landscape)
plt.show()

"""Step 1/2: make the static dataset"""

import os
total_sims = 0
test_dir = '/content/drive/MyDrive/selma/'
input = []
output = []
for file in os.listdir(test_dir):
    if file.endswith(".npy"):
      total_sims = total_sims + 1

      data = np.load(test_dir + file)
      rows,cols = data.shape
      my_image = np.zeros((rows,cols),dtype=int)
      for row in range(0,rows):
        for col in range(0,cols):
          if pd.isnull(data[row][col]) or data[row][col] < 200:
            my_image[row][col] = 0
          if 550 < data[row][col] < 560:
            my_image[row][col] = 555
          if 990 < data[row][col] < 1000:
            my_image[row][col] = 999

      ################ find the columns where the ground is wet ################
      wet_columns = []
      for col in range(138,cols):
        done = False
        row = 255
        while done == False:
          if my_image[row][col] == 555 and my_image[row-1][col] != 555:
            # you found the row corresponding to the ground
            done = True
          else:
            row = row - 1
        if my_image[row][col] == 555 and (my_image[row-1][col] == 999 or my_image[row-2][col] == 999 or my_image[row-3][col] == 999 or my_image[row-4][col] == 999 or my_image[row-5][col] == 999):
          # hit water 1, 2, 3, 4, or 5 rows above the ground
          wet_columns.append(col)
      ##########################################################################

      file_stripped = file[:-4]
      numbers_list = np.float32(file_stripped.split(","))  # <--- top_velocity + 8-point spline

      for _ in range(60000): #1008 * 60,000 = 60 M
        fire_col_1 = random.randint(138,cols-1)
        fire_col_2 = random.randint(138,cols-1)
        fire_col_3 = random.randint(138,cols-1)
        fires_put_out = 0
        if fire_col_1 in wet_columns:
          fires_put_out = fires_put_out + 1
        if fire_col_2 in wet_columns:
          fires_put_out = fires_put_out + 1
        if fire_col_3 in wet_columns:
          fires_put_out = fires_put_out + 1
        input.append([numbers_list[0],numbers_list[1],numbers_list[2],numbers_list[3],numbers_list[4],numbers_list[5],numbers_list[6],numbers_list[7],numbers_list[8],fire_col_1,fire_col_2,fire_col_3])
        output.append(fires_put_out/3)

print("total sims: "+str(total_sims))

input = np.float32(np.vstack(input))
output = np.float32(np.vstack(output))
print(input.shape)
print(output.shape)

print(np.max(input,0))
print(np.min(input,0))
print(np.max(output,0))
print(np.min(output,0))

# x[0] is top_velocity in range(0.01,0.05)
max, middle = 0.05, 0.5*(0.01+0.05)
input[:,0] = (input[:,0]-middle)/(max-middle)

# x[1] to x[8] are spline row values in range(180,254)
max, middle = 254., 0.5*(180.+254.)
for count in range(1,9):
  input[:,count] = (input[:,count]-middle)/(max-middle)

# x[9] to x[11] are fire column values in range (138,499)
max, middle = 499., 0.5*(138.+499.)
for count in range(9,12):
  input[:,count] = (input[:,count]-middle)/(max-middle)

# y[0] is probability in range(0,1)
max, middle = 1.0, 0.5*(0.0+1.0)
output[:,0] = (output[:,0]-middle)/(max-middle)

print("main data")
print(np.max(input, 0))
print(np.min(input,0))
print(np.max(output, 0))
print(np.min(output,0))

"""Step 2/2: make the dynamic dataset"""

# DO THIS OUTSIDE OF THE CUSTOM LOSS FUNCTION
# Step 1: load one of the simulation images

# DO THIS INSIDE THE CUSTOM LOSS FUNCTION
# Step 2: find where all the wet columns
# Step 3: randomly select fire_col_1, fire_col_2, fire_col_3
# Step 4: see what portion of the fires are extinguished

import os
total_sims = 0
test_dir = '/content/drive/MyDrive/selma/'
my_image_list = []
vel_and_spline_list = []
for file in os.listdir(test_dir):
    if file.endswith(".npy"):
      total_sims = total_sims + 1

      data = np.load(test_dir + file)
      rows,cols = data.shape
      my_image = np.zeros((rows,cols),dtype=int)
      for row in range(0,rows):
        for col in range(0,cols):
          if pd.isnull(data[row][col]) or data[row][col] < 200:
            my_image[row][col] = 0
          if 550 < data[row][col] < 560:
            my_image[row][col] = 555
          if 990 < data[row][col] < 1000:
            my_image[row][col] = 999

      file_stripped = file[:-4]
      numbers_list = np.float32(file_stripped.split(","))  # <--- top_velocity + 8-point spline

      my_image_list.append(my_image)
      vel_and_spline_list.append([numbers_list[0],numbers_list[1],numbers_list[2],numbers_list[3],numbers_list[4],numbers_list[5],numbers_list[6],numbers_list[7],numbers_list[8]])

print("total sims: "+str(total_sims))
my_image_list = np.dstack(my_image_list) # 256 x 500 x 1008 array
vel_and_spline_list = np.float32(np.vstack(vel_and_spline_list))

def custom_loss_wrapper(my_image_list,vel_and_spline_list):
  def custom_loss(y_true,y_pred):

    batch = 512

    # STEP 1: choose an input and output
    random_point = random.randint(0,1007) # pick any of the 1008 images
    my_image = my_image_list[:,:,[random_point]].reshape(256,500)
    vs = vel_and_spline_list[[random_point],:]  # [top_vel,s1,s2,s3,s4,s5,s6,s7,s8]

    # STEP 2: make scaled inputs for top_vel,s1,s2,s3,s4,s5,s6,s7,s8
    top_vel_max, top_vel_middle = 0.05,0.5*(0.01+0.05)
    tv = (vs[0][0] - top_vel_middle)/(top_vel_max-top_vel_middle)*np.ones((batch,1),dtype=np.float32)

    spline_max,spline_middle = 254.,0.5*(180.+254.)
    s1 = (vs[0][1] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)
    s2 = (vs[0][2] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)
    s3 = (vs[0][3] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)
    s4 = (vs[0][4] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)
    s5 = (vs[0][5] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)
    s6 = (vs[0][6] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)
    s7 = (vs[0][7] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)
    s8 = (vs[0][8] - spline_middle)/(spline_max-spline_middle)*np.ones((batch,1),dtype=np.float32)

    # STEP 3: find where the ground is wet
    wet_columns = []
    for col in range(138,500):
      done = False
      row = 255
      while done == False:
        if my_image[row][col] == 555 and my_image[row-1][col] != 555:
          # you found the row corresponding to the ground
          done = True
        else:
          row = row - 1
      if my_image[row][col] == 555 and (my_image[row-1][col] == 999 or my_image[row-2][col] == 999 or my_image[row-3][col] == 999 or my_image[row-4][col] == 999 or my_image[row-5][col] == 999):
        # hit water 1, 2, 3, 4, or 5 rows above the ground
        wet_columns.append(col)

    # STEP 4: make the raw inputs fire_col_1, fire_col_2, fire_col_3 & the raw output
    fire_col_1_list = []
    fire_col_2_list = []
    fire_col_3_list = []
    output_list = []
    for _ in range(batch):
      fire_col_1 = random.randint(138,cols-1)
      fire_col_2 = random.randint(138,cols-1)
      fire_col_3 = random.randint(138,cols-1)
      fires_put_out = 0
      if fire_col_1 in wet_columns:
        fires_put_out = fires_put_out + 1
      if fire_col_2 in wet_columns:
        fires_put_out = fires_put_out + 1
      if fire_col_3 in wet_columns:
        fires_put_out = fires_put_out + 1
      fire_col_1_list.append(fire_col_1)
      fire_col_2_list.append(fire_col_2)
      fire_col_3_list.append(fire_col_3)
      output_list.append(fires_put_out/3)
    fire_col_1_list = np.float32(np.vstack(fire_col_1_list))
    fire_col_2_list = np.float32(np.vstack(fire_col_2_list))
    fire_col_3_list = np.float32(np.vstack(fire_col_3_list))
    output_list = np.float32(np.vstack(output_list))

    # STEP 5: make the SCALED inputs fire_col_1, fire_col_2, fire_col_3
    fire_col_max,fire_col_middle = 499.,0.5*(138.+499.)
    f1 = (fire_col_1_list - fire_col_middle)/(fire_col_max-fire_col_middle)
    f2 = (fire_col_2_list - fire_col_middle)/(fire_col_max-fire_col_middle)
    f3 = (fire_col_3_list - fire_col_middle)/(fire_col_max-fire_col_middle)

    # STEP 6: make the SCALED output
    output_max,output_middle = 1.,0.5
    output_list = (output_list-output_middle)/(output_max-output_middle)
    output_actual_tensor = tf.convert_to_tensor(output_list)

    # STEP 7: calculate MSE of model prediction with ground truth
    output_predicted = model(tf.concat([tv,s1,s2,s3,s4,s5,s6,s7,s8,f1,f2,f3],1))
    wrapper_loss = K.mean(K.square(output_predicted-output_actual_tensor))

    return 4*wrapper_loss+K.mean(K.square(y_true-y_pred))
  return custom_loss

X = pd.DataFrame(data=input[0:,0:],index=[i for i in range(input.shape[0])],columns=['f'+str(i) for i in range(input.shape[1])])
Y = pd.DataFrame(data=output[0:,0:],index=[i for i in range(output.shape[0])],columns=['f'+str(i) for i in range(output.shape[1])])
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.1,random_state=0)

model = keras.models.Sequential()
model.add(keras.layers.Dense(150,activation='tanh',input_shape=(12,)))
model.add(keras.layers.Dense(150,activation='tanh'))
model.add(keras.layers.Dense(150,activation='tanh'))
model.add(keras.layers.Dense(150,activation='tanh'))
model.add(keras.layers.Dense(1,activation='tanh'))
optimizer = tf.keras.optimizers.Adam(learning_rate=0.000625,beta_1=0.9,beta_2=0.99)
model.compile(optimizer=optimizer,loss=custom_loss_wrapper(my_image_list,vel_and_spline_list))
model.fit(X_train,Y_train,epochs=20,batch_size=128)
model.save('/content/drive/MyDrive/MyProject/AI_firefighter_Selma_1.h5')
Y_pred = model.predict(X_test)
max, middle = 1.0, 0.5
Y_pred = Y_pred*(max-middle)+middle
# if probabilities are 0.00, 0.50, and 1.00
# you can make two hyperbolic tangents where the center is in the middle, i.e., 0.25 and 0.75

# if probabilities are 0.00, 0.33, 0.66, and 1.00
# we need 3 hyperbolic tangents with centers at 0.1665, 0.500, 0.8333

Y_pred = 0.1665*tf.math.tanh(125*(Y_pred-0.1665))+0.1665*tf.math.tanh(125*(Y_pred-0.5000))+0.1665*tf.math.tanh(125*(Y_pred-0.8333))+0.50
Y_test_copy = Y_test.copy()
Y_test_copy = Y_test_copy*(max-middle)+middle
mse=mean_squared_error(Y_pred,Y_test_copy)
print("Unscaled MSE is "+str(mse))

lr = [0.0005,0.0004,0.0003,0.0002,0.0001,0.00005]
epoch_list = [20,20,20,1,1,1]
for count in range(0,6):
  model = keras.models.load_model('/content/drive/MyDrive/MyProject/AI_firefighter_Selma_1.h5',custom_objects={'custom_loss':custom_loss_wrapper(my_image_list,vel_and_spline_list)})
  K.set_value(model.optimizer.learning_rate, lr[count])
  model.fit(X_train, Y_train, epochs=epoch_list[count], batch_size=128)
  model.save('/content/drive/MyDrive/MyProject/AI_firefighter_Selma_1.h5')
  Y_pred = model.predict(X_test)
  max, middle = 1.0, 0.5
  Y_pred = Y_pred*(max-middle)+middle
  Y_pred = 0.1665*tf.math.tanh(125*(Y_pred-0.1665))+0.1665*tf.math.tanh(125*(Y_pred-0.5000))+0.1665*tf.math.tanh(125*(Y_pred-0.8333))+0.50
  Y_test_copy = Y_test.copy()
  Y_test_copy = Y_test_copy*(max-middle)+middle
  mse=mean_squared_error(Y_pred,Y_test_copy)
  print("Unscaled MSE is "+str(mse))

# 0.000625,0.0005,0.0004,0.0003,0.0002,0.0001,0.00005 (20 epochs each)

"""some testing"""

from tensorflow.keras.models import load_model
import tensorflow.keras
import tensorflow as tf
keras_model1 = tensorflow.keras.models.load_model('/content/drive/MyDrive/MyProject/AI_firefighter_Selma_1.h5',custom_objects={'custom_loss':custom_loss_wrapper(my_image_list,vel_and_spline_list)}, compile=False)
keras_model1._name = 'model1'
keras_model2 = tensorflow.keras.models.load_model('/content/drive/MyDrive/MyProject/AI_firefighter_Selma_2.h5',custom_objects={'custom_loss':custom_loss_wrapper(my_image_list,vel_and_spline_list)}, compile=False)
keras_model2._name = 'model2'
models = [keras_model1, keras_model2]
model_input = tf.keras.Input(shape=(11,))
model_outputs = [model(model_input) for model in models]
ensemble_output = tf.keras.layers.Average()(model_outputs)
ensemble_model = tf.keras.Model(inputs=model_input, outputs=ensemble_output)
Y_pred = ensemble_model.predict(X_test)
print(str(mean_squared_error(Y_pred,Y_test))+" (scaled)")
max, middle = 1.0, 0.5
Y_pred = Y_pred*(max-middle)+middle
Y_pred = 0.1665*tf.math.tanh(125*(Y_pred-0.1665))+0.1665*tf.math.tanh(125*(Y_pred-0.5000))+0.1665*tf.math.tanh(125*(Y_pred-0.8333))+0.50
Y_test_copy = Y_test.copy()
Y_test_copy = Y_test_copy*(max-middle)+middle
mse=mean_squared_error(Y_pred,Y_test_copy)
print("Unscaled MSE is "+str(mse))

sample_output = np.load('/content/drive/MyDrive/selma/0.04335,221,196,201,191,195,217,230,182.npy')
plt.imshow(sample_output,cmap='jet',interpolation='nearest')
plt.show()

y_points = [221,196,201,191,195,217,230,182] # get from selma folder

########### scale y_points ###########
max, middle = 254., 0.5*(180.+254.)
y0 = (y_points[0]-middle)/(max-middle)
y1 = (y_points[1]-middle)/(max-middle)
y2 = (y_points[2]-middle)/(max-middle)
y3 = (y_points[3]-middle)/(max-middle)
y4 = (y_points[4]-middle)/(max-middle)
y5 = (y_points[5]-middle)/(max-middle)
y6 = (y_points[6]-middle)/(max-middle)
y7 = (y_points[7]-middle)/(max-middle)
######################################

# STEP 1/2: pick fire_col_1
# STEP 2/2: pick fire_col_2
fire_col_1 = 480.
fire_col_2 = 485.

#### scale fire_col_1, fire_col_2 ####
max, middle = 499., 0.5*(138.+499.)
fire_col_1 = (fire_col_1-middle)/(max-middle)
fire_col_2 = (fire_col_2-middle)/(max-middle)
######################################

test_input = []
for count in range(0,501):
  top_velocity = -1.+2.*(count/500.)
  test_input.append([top_velocity,y0,y1,y2,y3,y4,y5,y6,y7,fire_col_1,fire_col_2])
test_input = np.vstack(test_input)
X_validation = pd.DataFrame(data=test_input[0:,0:],index=[i for i in range(test_input.shape[0])],columns=['f'+str(i) for i in range(test_input.shape[1])])
Y_validation = ensemble_model.predict(X_validation)
max, middle = 1.0, 0.5
Y_validation = Y_validation*(max-middle)+middle
Y_validation = 0.25*tf.math.tanh(125*(Y_validation-0.25))+0.25*tf.math.tanh(125*(Y_validation-0.75))+0.50
Y_validation = np.array(Y_validation)
row_with_max_value = np.argmax(Y_validation[:,0])
print("row = "+str(row_with_max_value))
max, middle = 0.05, 0.5*(0.01+0.05)
unscaled_velocity = (-1+2*(row_with_max_value/500))*(max-middle)+middle
print("top_velocity = "+str(unscaled_velocity))
print("portion of fire extinguished = "+str(Y_validation[row_with_max_value][0]))